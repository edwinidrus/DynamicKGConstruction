{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-vscode-title",
   "metadata": {},
   "source": [
    "# SKGB - Semantic Knowledge Graph Builder (VS Code + Google Colab)\n",
    "\n",
    "This notebook demonstrates the full **DynamicKGConstruction** pipeline using VS Code connected to a Google Colab runtime.\n",
    "\n",
    "**PDF -> Docling Markdown -> Semantic Chunks -> itext2kg Knowledge Graph -> Visualization**\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "### Option 1: Google Colab VS Code Extension (Recommended)\n",
    "1. Install the **Google Colab** extension in VS Code\n",
    "2. Start a Colab runtime (from colab.research.google.com or within Colab)\n",
    "3. In VS Code: `Cmd/Ctrl + Shift + P` → \"Colab: Connect to Runtime\"\n",
    "4. Select your running Colab instance\n",
    "\n",
    "### Option 2: Manual Remote Jupyter\n",
    "1. Start Jupyter server in Colab: `!jupyter notebook --NotebookApp.allow_origin='*' --port=8888`\n",
    "2. Get the connection token\n",
    "3. In VS Code: Add Jupyter server → connect to `http://localhost:8888?token=xxx`\n",
    "\n",
    "### Runtime Settings\n",
    "- Go to **Runtime → Change runtime type** → Select **T4 GPU** (recommended for faster LLM inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-env-detection",
   "metadata": {},
   "source": [
    "## 1. Environment Detection\n",
    "\n",
    "Detect whether we're running in Colab, local, or VS Code with Colab extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-env-check",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment detection\n",
    "import sys\n",
    "\n",
    "def detect_environment():\n",
    "    \"\"\"Detect the current environment.\"\"\"\n",
    "    env = {\n",
    "        \"in_colab\": False,\n",
    "        \"in_vscode\": False,\n",
    "        \"colab_extension\": False\n",
    "    }\n",
    "\n",
    "    # Check for Colab\n",
    "    try:\n",
    "        from google.colab import _is_colab_env\n",
    "        env[\"in_colab\"] = _is_colab_env()\n",
    "    except ImportError:\n",
    "        pass\n",
    "\n",
    "    # Check if running in VS Code\n",
    "    env[\"in_vscode\"] = hasattr(sys, \"ps1\") or \"VSCODE\" in sys.prefix\n",
    "\n",
    "    # Check for Colab extension indicators\n",
    "    try:\n",
    "        import json\n",
    "        import os\n",
    "        # Check for colab runtime connection\n",
    "        if os.path.exists(\"/usr/local/colab_user\"):\n",
    "            env[\"colab_extension\"] = True\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    return env\n",
    "\n",
    "env = detect_environment()\n",
    "print(f\"Environment detected:\")\n",
    "print(f\"  In Google Colab: {env['in_colab']}\")\n",
    "print(f\"  In VS Code:     {env['in_vscode']}\")\n",
    "print(f\"  Colab Extension: {env['colab_extension']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-ollama-setup",
   "metadata": {},
   "source": [
    "## 2. Install Ollama\n",
    "\n",
    "Ollama runs inside the Colab runtime. You need to install and pull models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-ollama-install",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Ollama (run this once per Colab session)\n",
    "# !sudo apt-get install zstd  # if needed\n",
    "# !curl -fsSL https://ollama.com/install.sh | sh\n",
    "\n",
    "# Or use the Ollama that may already be available in your Colab environment\n",
    "# Check if ollama is available\n",
    "!which ollama || echo \"Ollama not found - may need installation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-ollama-start",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import time\n",
    "\n",
    "# Start Ollama server in background\n",
    "ollama_proc = subprocess.Popen(\n",
    "    [\"ollama\", \"serve\"],\n",
    "    stdout=subprocess.DEVNULL,\n",
    "    stderr=subprocess.DEVNULL,\n",
    ")\n",
    "time.sleep(3)\n",
    "print(f\"Ollama server started (PID {ollama_proc.pid})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-ollama-pull",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull required models\n",
    "# Adjust model sizes based on your Colab GPU VRAM\n",
    "\n",
    "LLM_MODEL = \"qwen2.5\"  # ~4.7 GB (use qwen2.5:7b for less VRAM)\n",
    "EMBEDDINGS_MODEL = \"nomic-embed-text\"  # ~274 MB\n",
    "\n",
    "# Uncomment to pull models (only needed once)\n",
    "# !ollama pull {LLM_MODEL}\n",
    "# !ollama pull {EMBEDDINGS_MODEL}\n",
    "\n",
    "# Verify models are available\n",
    "# !ollama list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-install-skgb",
   "metadata": {},
   "source": [
    "## 3. Install DynamicKGConstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-clone-repo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository (if not already present)\n",
    "!git clone https://github.com/edwinidrus/DynamicKGConstruction.git 2>/dev/null || echo \"Already cloned\"\n",
    "\n",
    "# Change to project directory\n",
    "%cd DynamicKGConstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-install-deps",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-verify-import",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify SKGB imports correctly\n",
    "from DynamicKGConstruction.skgb import SKGBConfig, run_pipeline\n",
    "print(\"SKGB imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-upload-pdf",
   "metadata": {},
   "source": [
    "## 4. Upload a PDF\n",
    "\n",
    "Upload your PDF to the Colab runtime. The file will be available for processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-logging",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging for debugging\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(levelname)s:%(name)s:%(message)s\")\n",
    "logging.getLogger(\"DynamicKGConstruction.skgb.adapters.itext2kg_adapter\").setLevel(logging.DEBUG)\n",
    "print(\"Logging configured - adapter debug messages will appear below.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-create-input-dir",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "INPUT_DIR = Path(\"input_docs\")\n",
    "INPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Check if running in Colab (including VS Code with Colab extension)\n",
    "try:\n",
    "    from google.colab import files\n",
    "    print(\"Running in Colab - use the file upload button below:\")\n",
    "    uploaded = files.upload()\n",
    "    for filename, data in uploaded.items():\n",
    "        dest = INPUT_DIR / filename\n",
    "        dest.write_bytes(data)\n",
    "        print(f\"Saved: {dest}\")\n",
    "except ImportError:\n",
    "    print(\"Not in Colab - please place your PDF in 'input_docs/' manually\")\n",
    "    print(f\"Current directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-sample-pdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option: Download a sample PDF\n",
    "SAMPLE_URL = \"https://arxiv.org/pdf/1706.03762\"  # Attention Is All You Need\n",
    "SAMPLE_PATH = INPUT_DIR / \"attention_is_all_you_need.pdf\"\n",
    "\n",
    "if not SAMPLE_PATH.exists():\n",
    "    !wget -q -O \"{SAMPLE_PATH}\" \"{SAMPLE_URL}\"\n",
    "    print(f\"Downloaded sample PDF to {SAMPLE_PATH}\")\n",
    "else:\n",
    "    print(f\"Sample PDF already exists at {SAMPLE_PATH}\")\n",
    "\n",
    "# List all PDFs\n",
    "pdfs = list(INPUT_DIR.glob(\"*.pdf\"))\n",
    "print(f\"\\nPDFs in {INPUT_DIR}/: {[p.name for p in pdfs]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-pipeline-config",
   "metadata": {},
   "source": [
    "## 5. Configure and Run the SKGB Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-config",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from DynamicKGConstruction.skgb import SKGBConfig, run_pipeline\n",
    "\n",
    "# Select input PDF\n",
    "pdf_path = list(Path(\"input_docs\").glob(\"*.pdf\"))[0]\n",
    "print(f\"Input PDF: {pdf_path}\")\n",
    "\n",
    "# Create pipeline configuration\n",
    "# Note: Ollama runs in Colab, so use localhost:11434\n",
    "cfg = SKGBConfig.from_out_dir(\n",
    "    \"skgb_output\",\n",
    "    llm_model=\"qwen2.5\",  # Use smaller model for Colab\n",
    "    embeddings_model=\"nomic-embed-text\",\n",
    "    ollama_base_url=\"http://localhost:11434\",\n",
    "    temperature=0.0,\n",
    "    ent_threshold=0.8,\n",
    "    rel_threshold=0.7,\n",
    "    max_workers=2,        # Keep low for Colab\n",
    "    min_chunk_words=200,\n",
    "    max_chunk_words=800,\n",
    "    overlap_words=0,\n",
    ")\n",
    "\n",
    "print(f\"\\nPipeline config:\")\n",
    "print(f\"  LLM model:        {cfg.llm_model}\")\n",
    "print(f\"  Embeddings model: {cfg.embeddings_model}\")\n",
    "print(f\"  Ollama URL:       {cfg.ollama_base_url}\")\n",
    "print(f\"  Output dir:       {cfg.out_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-run-pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the full pipeline\n",
    "# This may take several minutes depending on PDF size and model\n",
    "\n",
    "result = run_pipeline(pdf_path, cfg)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Pipeline completed!\")\n",
    "print(f\"  Markdown dir:  {result.build_docling_dir}\")\n",
    "print(f\"  Chunks JSON:   {result.chunks_json_path}\")\n",
    "print(f\"  KG output dir: {result.kg_output_dir}\")\n",
    "print(f\"  Neo4j Cypher:  {result.neo4j_cypher_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-explore-results",
   "metadata": {},
   "source": [
    "## 6. Explore the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-list-outputs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all output files\n",
    "print(\"Output files:\")\n",
    "for f in sorted(result.kg_output_dir.rglob(\"*\")):\n",
    "    if f.is_file():\n",
    "        size = f.stat().st_size\n",
    "        print(f\"  {f.name:40s} {size:>8,} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-construction-report",
   "metadata": {},
   "source": [
    "### 6.1 Construction Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-report",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_path = result.kg_output_dir / \"construction_report.txt\"\n",
    "print(report_path.read_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-kg-json",
   "metadata": {},
   "source": [
    "### 6.2 Knowledge Graph JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-kg-json-display",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "kg_json_path = result.kg_output_dir / \"knowledge_graph.json\"\n",
    "kg_data = json.loads(kg_json_path.read_text())\n",
    "\n",
    "nodes = kg_data.get(\"nodes\", [])\n",
    "edges = kg_data.get(\"edges\", [])\n",
    "\n",
    "print(f\"Total nodes: {len(nodes)}\")\n",
    "print(f\"Total edges: {len(edges)}\")\n",
    "print(f\"\\n--- First 10 Nodes ---\")\n",
    "for n in nodes[:10]:\n",
    "    print(f\"  {n['name']:40s}  label={n.get('label', '')}\")\n",
    "\n",
    "print(f\"\\n--- First 10 Edges ---\")\n",
    "for e in edges[:10]:\n",
    "    print(f\"  {e['source'][:25]:25s} --[{e['relation'][:20]}]--> {e['target'][:25]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-dataframes",
   "metadata": {},
   "source": [
    "### 6.3 Nodes & Edges as DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-dataframes-display",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_nodes = pd.read_csv(result.kg_output_dir / \"kg_nodes.csv\")\n",
    "df_edges = pd.read_csv(result.kg_output_dir / \"kg_edges.csv\")\n",
    "\n",
    "print(f\"Nodes shape: {df_nodes.shape}\")\n",
    "display(df_nodes.head(10))\n",
    "\n",
    "print(f\"\\nEdges shape: {df_edges.shape}\")\n",
    "display(df_edges.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-visualization",
   "metadata": {},
   "source": [
    "### 6.4 Interactive Knowledge Graph Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-viz-display",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the PyVis interactive graph\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "viz_path = result.kg_output_dir / \"kg_visualization.html\"\n",
    "if viz_path.exists():\n",
    "    display(HTML(viz_path.read_text()))\n",
    "else:\n",
    "    print(\"Visualization file not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-networkx",
   "metadata": {},
   "source": [
    "### 6.5 NetworkX Graph Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-networkx-stats",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "G = nx.read_graphml(str(result.kg_output_dir / \"knowledge_graph.graphml\"))\n",
    "\n",
    "print(f\"Graph type:       {type(G).__name__}\")\n",
    "print(f\"Number of nodes:  {G.number_of_nodes()}\")\n",
    "print(f\"Number of edges:  {G.number_of_edges()}\")\n",
    "print(f\"Density:          {nx.density(G):.4f}\")\n",
    "\n",
    "if G.number_of_nodes() > 0:\n",
    "    degree_sorted = sorted(G.degree(), key=lambda x: x[1], reverse=True)\n",
    "    print(f\"\\nTop 10 nodes by degree:\")\n",
    "    for name, deg in degree_sorted[:10]:\n",
    "        print(f\"  {name:40s}  degree={deg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-chunks",
   "metadata": {},
   "source": [
    "### 6.6 Semantic Chunks Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-chunks-display",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = json.loads(result.chunks_json_path.read_text())\n",
    "print(f\"Total chunks: {len(chunks)}\\n\")\n",
    "\n",
    "for i, ch in enumerate(chunks[:3]):\n",
    "    print(f\"--- Chunk {i} ---\")\n",
    "    print(f\"  ID:      {ch.get('chunk_id', 'N/A')}\")\n",
    "    print(f\"  Section: {ch.get('section_title', 'N/A')}\")\n",
    "    content = ch.get('content', '')\n",
    "    print(f\"  Content: {content[:300]}{'...' if len(content) > 300 else ''}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-neo4j",
   "metadata": {},
   "source": [
    "## 7. Neo4j Cypher Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-neo4j-display",
   "metadata": {},
   "outputs": [],
   "source": [
    "cypher_path = result.neo4j_cypher_path\n",
    "if cypher_path.exists():\n",
    "    print(cypher_path.read_text())\n",
    "else:\n",
    "    print(\"Neo4j Cypher file not generated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-download",
   "metadata": {},
   "source": [
    "## 8. Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-zip-download",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Zip all outputs\n",
    "archive_path = shutil.make_archive(\"skgb_results\", \"zip\", \".\", \"skgb_output\")\n",
    "print(f\"Archive created: {archive_path}\")\n",
    "\n",
    "# Try to trigger download (works in Colab)\n",
    "try:\n",
    "    from google.colab import files\n",
    "    files.download(archive_path)\n",
    "    print(\"Download initiated - check your browser downloads\")\n",
    "except ImportError:\n",
    "    print(\"Not in Colab - find the zip at:\", archive_path)\n",
    "    print(\"\\nTo download from Colab manually:\")\n",
    "    print(\"1. Go to Colab: https://colab.research.google.com\")\n",
    "    print(\"2. Open the Files tab (folder icon on the left)\")\n",
    "    print(\"3. Right-click 'skgb_results.zip' and download\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-cleanup",
   "metadata": {},
   "source": [
    "## 9. Cleanup\n",
    "\n",
    "Stop the Ollama server when done to free resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-ollama-stop",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the Ollama server\n",
    "try:\n",
    "    ollama_proc.terminate()\n",
    "    ollama_proc.wait()\n",
    "    print(\"Ollama server stopped.\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not stop Ollama: {e}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "SKGB - VS Code + Colab",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "a1d48bbd92d1f9bf50c7c18471b13f4eb1e8b7a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
