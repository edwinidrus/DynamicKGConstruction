{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pv3YpBMWrGn"
      },
      "source": [
        "# SKGB - Semantic Knowledge Graph Builder (Colab Demo)\n",
        "\n",
        "This notebook demonstrates the full **DynamicKGConstruction** pipeline:\n",
        "\n",
        "**PDF -> Docling Markdown -> Semantic Chunks -> itext2kg Knowledge Graph -> Visualization**\n",
        "\n",
        "It runs Ollama with `qwen2.5` locally inside Colab (CPU or GPU).\n",
        "\n",
        "> **Runtime**: Go to *Runtime -> Change runtime type* and select **T4 GPU** for faster LLM inference (optional but recommended)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Giu5WKwuWrGq"
      },
      "source": [
        "## 1. Install Ollama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOvhgnhwWrGr",
        "outputId": "3e3624bd-fb6c-4d79-e6bf-b134177530da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> Installing ollama to /usr/local\n",
            "\u001b[1m\u001b[31mERROR:\u001b[m This version requires zstd for extraction. Please install zstd and try again:\n",
            "  - Debian/Ubuntu: sudo apt-get install zstd\n",
            "  - RHEL/CentOS/Fedora: sudo dnf install zstd\n",
            "  - Arch: sudo pacman -S zstd\n"
          ]
        }
      ],
      "source": [
        "# Install Ollama\n",
        "# sudo apt-get install zstd\n",
        "# curl -fsSL https://ollama.com/install.sh | sh\n",
        "# ollama serve & ollama run qwen2.5:32b & ollama pull nomic-embed-text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxovemMsWrGs",
        "outputId": "11bf8b40-d5b1-41b6-8d60-b3a15c1bc9af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ollama server started (PID 2620)\n"
          ]
        }
      ],
      "source": [
        "# # Start the Ollama server in the background\n",
        "# # import subprocess, time\n",
        "\n",
        "# # ollama_proc = subprocess.Popen(\n",
        "# #     [\"ollama\", \"serve\"],\n",
        "# #     stdout=subprocess.DEVNULL,\n",
        "# #     stderr=subprocess.DEVNULL,\n",
        "# # )\n",
        "# time.sleep(3)  # wait for the server to be ready\n",
        "# print(f\"Ollama server started (PID {ollama_proc.pid})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GjUMj7BNWrGs"
      },
      "outputs": [],
      "source": [
        "# Pull the models required by the pipeline\n",
        "# Using qwen2.5 (7b default) - smaller model suitable for Colab\n",
        "# # Change to qwen2.5:32b if you have enough VRAM\n",
        "# LLM_MODEL = \"qwen2.5\"  # ~4.7 GB\n",
        "# EMBEDDINGS_MODEL = \"nomic-embed-text\"  # ~274 MB\n",
        "#ollama serve & ollama pull qwen2.5:32b & ollama pull nomic-embed-text\n",
        "# !ollama pull {LLM_MODEL}\n",
        "# !ollama pull {EMBEDDINGS_MODEL}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qovvRm_jWrGt"
      },
      "outputs": [],
      "source": [
        "# Verify Ollama is running and models are available\n",
        "# !ollama list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WKO8NGyr8slR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuqLj8gGWrGt"
      },
      "source": [
        "## 2. Install DynamicKGConstruction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxQ7JdaGWrGt",
        "outputId": "d07d33ac-d279-480a-f6d5-7d9316b5f4e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Already cloned\n",
            "/content/DynamicKGConstruction\n"
          ]
        }
      ],
      "source": [
        "# Clone the repository\n",
        "!git clone https://github.com/edwinidrus/DynamicKGConstruction.git 2>/dev/null || echo \"Already cloned\"\n",
        "%cd DynamicKGConstruction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0_cD46uWrGu",
        "outputId": "e1a1fcb5-84b7-4975-8012-673511682eb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution ~qlalchemy (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m107.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: Ignoring invalid distribution ~qlalchemy (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~qlalchemy (/usr/local/lib/python3.12/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Install dependencies\n",
        "!pip install -q -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNBJBgaCAjBD"
      },
      "outputs": [],
      "source": [
        "# Fix for the itext2kg IndexError - add defensive error handling\n",
        "# Run this cell BEFORE running the pipeline if you get \"IndexError: list index out of range\"\n",
        "\n",
        "# Patch the itext2kg adapter to handle empty atomic KG lists\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# Create a patched version of the adapter\n",
        "patch_code = '''\n",
        "import functools\n",
        "import asyncio\n",
        "from typing import Dict, List\n",
        "\n",
        "def _safe_parallel_atomic_merge(original_func):\n",
        "    \"\"\"Wrapper to handle empty atomic KG lists in itext2kg.\"\"\"\n",
        "    @functools.wraps(original_func)\n",
        "    def wrapper(self, kgs, existing_kg=None, rel_threshold=0.7, ent_threshold=0.8, max_workers=8):\n",
        "        # Handle empty kgs list\n",
        "        if not kgs or len(kgs) == 0:\n",
        "            print(\"‚ö†Ô∏è  Warning: No atomic KGs to merge (empty quintuples). Returning empty KG.\")\n",
        "            # Return empty KnowledgeGraph\n",
        "            from itext2kg.graphs.knowledge_graph import KnowledgeGraph\n",
        "            return KnowledgeGraph()\n",
        "        return original_func(self, kgs, existing_kg, rel_threshold, ent_threshold, max_workers)\n",
        "    return wrapper\n",
        "\n",
        "def apply_itext2kg_patch():\n",
        "    \"\"\"Apply the patch to itext2kg's Atom class.\"\"\"\n",
        "    try:\n",
        "        from itext2kg.atom import Atom\n",
        "        original_merge = Atom.parallel_atomic_merge\n",
        "        Atom.parallel_atomic_merge = _safe_parallel_atomic_merge(original_merge)\n",
        "        print(\"‚úÖ Patched itext2kg.parallel_atomic_merge to handle empty atomic KGs\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è  Could not apply patch: {e}\")\n",
        "\n",
        "apply_itext2kg_patch()\n",
        "'''\n",
        "\n",
        "# Write patch to a file and execute it\n",
        "patch_path = \"/tmp/itext2kg_patch.py\"\n",
        "with open(patch_path, \"w\") as f:\n",
        "    f.write(patch_code)\n",
        "\n",
        "# Apply the patch\n",
        "exec(open(patch_path).read())\n",
        "\n",
        "print(\"\\\\nüîß Patch applied! You can now run the pipeline cell.\")\n",
        "print(\"If the issue persists, try:\")\n",
        "print(\"  1. Lowering thresholds: ent_threshold=0.6, rel_threshold=0.5\")\n",
        "print(\"  2. Using a different model: llm_model='llama3.1:8b'\")\n",
        "print(\"  3. Checking if Ollama is returning valid JSON quintuples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üîß FIX for itext2kg IndexError - MUST run this AFTER SKGB import but BEFORE pipeline\n",
        "# This patches the itext2kg library to handle empty atomic KG lists\n",
        "\n",
        "print(\"Applying itext2kg patch...\")\n",
        "\n",
        "try:\n",
        "    import itext2kg.atom.atom as atom_module\n",
        "    import functools\n",
        "    \n",
        "    # Store original function reference\n",
        "    _original_func = atom_module.Atom.parallel_atomic_merge\n",
        "    \n",
        "    @functools.wraps(_original_func)\n",
        "    def _safe_parallel_atomic_merge(self, kgs, existing_kg=None, rel_threshold=0.7, ent_threshold=0.8, max_workers=8):\n",
        "        \"\"\"Patched version that handles empty kgs list.\"\"\"\n",
        "        if not kgs:\n",
        "            print(\"‚ö†Ô∏è  No atomic KGs to merge (empty quintuples). Returning empty KG.\")\n",
        "            from itext2kg.graphs.knowledge_graph import KnowledgeGraph\n",
        "            return KnowledgeGraph()\n",
        "        return _original_func(self, kgs, existing_kg, rel_threshold, ent_threshold, max_workers)\n",
        "    \n",
        "    # Apply patch\n",
        "    atom_module.Atom.parallel_atomic_merge = _safe_parallel_atomic_merge\n",
        "    print(\"‚úÖ Patch applied! itext2kg will now handle empty atomic KG lists gracefully.\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Failed to apply patch: {e}\")\n",
        "    print(\"Alternative: Try using llama3.1:8b model or lower thresholds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJiSooE-WrGu",
        "outputId": "33da5609-cf1a-491c-d3ba-61306ae5799b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SKGB imported successfully\n"
          ]
        }
      ],
      "source": [
        "# Verify the SKGB package imports correctly\n",
        "from DynamicKGConstruction.skgb import SKGBConfig, run_pipeline\n",
        "print(f\"SKGB imported successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uTPTcbwWrGv"
      },
      "source": [
        "## 3. Upload a PDF\n",
        "\n",
        "Upload your own PDF or use the sample download below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "ts2CLl6qWrGv",
        "outputId": "816eaa3b-1706-4b7a-a33f-e63472bb113a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Click the button below to upload a PDF file:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fc73d1a5-3ce3-4a9e-a34a-d6c8c4a88548\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-fc73d1a5-3ce3-4a9e-a34a-d6c8c4a88548\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "INPUT_DIR = Path(\"input_docs\")\n",
        "INPUT_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# Option A: Upload from your computer\n",
        "try:\n",
        "    from google.colab import files\n",
        "    print(\"Click the button below to upload a PDF file:\")\n",
        "    uploaded = files.upload()\n",
        "    for filename, data in uploaded.items():\n",
        "        dest = INPUT_DIR / filename\n",
        "        dest.write_bytes(data)\n",
        "        print(f\"Saved: {dest}\")\n",
        "except ImportError:\n",
        "    print(\"Not running in Colab - place your PDF in input_docs/ manually\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYCl3uTBWrGw",
        "outputId": "89719c27-dc4b-4652-dfdf-27bea3cee5ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloaded sample PDF to input_docs/attention_is_all_you_need.pdf\n",
            "\n",
            "PDFs in input_docs/: ['attention_is_all_you_need.pdf']\n"
          ]
        }
      ],
      "source": [
        "# Option B: Download a sample PDF (a short Wikipedia article)\n",
        "# Skip this cell if you already uploaded your own PDF above\n",
        "\n",
        "SAMPLE_URL = \"https://arxiv.org/pdf/1706.03762\"  # \"Attention Is All You Need\"\n",
        "SAMPLE_PATH = INPUT_DIR / \"attention_is_all_you_need.pdf\"\n",
        "\n",
        "if not SAMPLE_PATH.exists():\n",
        "    !wget -q -O \"{SAMPLE_PATH}\" \"{SAMPLE_URL}\"\n",
        "    print(f\"Downloaded sample PDF to {SAMPLE_PATH}\")\n",
        "else:\n",
        "    print(f\"Sample PDF already exists at {SAMPLE_PATH}\")\n",
        "\n",
        "# List all PDFs in the input directory\n",
        "pdfs = list(INPUT_DIR.glob(\"*.pdf\"))\n",
        "print(f\"\\nPDFs in {INPUT_DIR}/: {[p.name for p in pdfs]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPS02YgEWrGw"
      },
      "source": [
        "## 4. Configure and Run the SKGB Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ld2iFDFWrGw",
        "outputId": "545455a0-1e77-4cfc-8e3f-b331539088fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input PDF: input_docs/attention_is_all_you_need.pdf\n",
            "\n",
            "Pipeline config:\n",
            "  LLM model:        qwen2.5:32b\n",
            "  Embeddings model: nomic-embed-text\n",
            "  Ollama URL:       http://localhost:11434\n",
            "  Output dir:       skgb_output\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "from DynamicKGConstruction.skgb import SKGBConfig, run_pipeline\n",
        "\n",
        "# Pick the first PDF found (or set your own path)\n",
        "pdf_path = list(Path(\"input_docs\").glob(\"*.pdf\"))[0]\n",
        "print(f\"Input PDF: {pdf_path}\")\n",
        "\n",
        "# Create the pipeline configuration\n",
        "cfg = SKGBConfig.from_out_dir(\n",
        "    \"skgb_output\",\n",
        "    llm_model=\"qwen2.5:32b\",\n",
        "    embeddings_model=\"nomic-embed-text\",\n",
        "    ollama_base_url=\"http://localhost:11434\",\n",
        "    temperature=0.0,\n",
        "    ent_threshold=0.8,\n",
        "    rel_threshold=0.7,\n",
        "    max_workers=2,        # keep low for Colab\n",
        "    min_chunk_words=200,\n",
        "    max_chunk_words=800,\n",
        "    overlap_words=0,\n",
        ")\n",
        "\n",
        "print(f\"\\nPipeline config:\")\n",
        "print(f\"  LLM model:        {cfg.llm_model}\")\n",
        "print(f\"  Embeddings model: {cfg.embeddings_model}\")\n",
        "print(f\"  Ollama URL:       {cfg.ollama_base_url}\")\n",
        "print(f\"  Output dir:       {cfg.out_dir}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "55UdX_UpWrGx",
        "outputId": "e9002fc1-ddf6-4cdb-84cd-7e30e3d37ab7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing: input_docs/attention_is_all_you_need.pdf\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì Saved parsed text to: skgb_output/build_docling/attention_is_all_you_need_pdf.md\n",
            "\n",
            "Completed processing 1 files.\n",
            "[2026-02-15 19:26:25] [ WARNING] [itext2kg.llm_output_parsing.langchain_output_parser] ‚ö†Ô∏è  Could not auto-detect provider from model: chatollama\n",
            "[2026-02-15 19:26:25] [ WARNING] [itext2kg.llm_output_parsing.langchain_output_parser]    Module: langchain_ollama.chat_models\n",
            "[2026-02-15 19:26:25] [ WARNING] [itext2kg.llm_output_parsing.langchain_output_parser]    Using conservative defaults for unknown provider\n",
            "[2026-02-15 19:26:25] [    INFO] [itext2kg.llm_output_parsing.langchain_output_parser] üîç Detected LLM Provider: Unknown\n",
            "[2026-02-15 19:26:25] [    INFO] [itext2kg.llm_output_parsing.langchain_output_parser] üìä Rate Limiting Config: 5 requests/batch, 4000 tokens/batch\n",
            "[2026-02-15 19:26:25] [    INFO] [itext2kg.itext2kg.atom.atom] ------- Extracting Quintuples---------\n",
            "[2026-02-15 19:26:28] [    INFO] [itext2kg.llm_output_parsing.langchain_output_parser] üì¶ Split 28 prompts into 9 batches for Unknown API\n",
            "[2026-02-15 19:26:28] [    INFO] [itext2kg.llm_output_parsing.langchain_output_parser] üöÄ Processing 28 contexts in 9 batches for Unknown API\n",
            "[2026-02-15 19:26:28] [    INFO] [itext2kg.llm_output_parsing.langchain_output_parser] üìã Processing batch 1/9 with 4 requests (Unknown)\n",
            "[2026-02-15 19:28:12] [    INFO] [itext2kg.llm_output_parsing.langchain_output_parser] üò¥ Sleeping 10.0s between batches for Unknown\n",
            "[2026-02-15 19:28:22] [    INFO] [itext2kg.llm_output_parsing.langchain_output_parser] üìã Processing batch 2/9 with 4 requests (Unknown)\n",
            "[2026-02-15 19:30:19] [    INFO] [itext2kg.llm_output_parsing.langchain_output_parser] üò¥ Sleeping 10.0s between batches for Unknown\n",
            "[2026-02-15 19:30:29] [    INFO] [itext2kg.llm_output_parsing.langchain_output_parser] üìã Processing batch 3/9 with 4 requests (Unknown)\n",
            "[2026-02-15 19:32:26] [    INFO] [itext2kg.llm_output_parsing.langchain_output_parser] üò¥ Sleeping 10.0s between batches for Unknown\n",
            "[2026-02-15 19:32:36] [    INFO] [itext2kg.llm_output_parsing.langchain_output_parser] üìã Processing batch 4/9 with 3 requests (Unknown)\n",
            "[2026-02-15 19:33:43] [    INFO] [itext2kg.llm_output_parsing.langchain_output_parser] üò¥ Sleeping 10.0s between batches for Unknown\n",
            "[2026-02-15 19:33:53] [    INFO] [itext2kg.llm_output_parsing.langchain_output_parser] üìã Processing batch 5/9 with 4 requests (Unknown)\n",
            "[2026-02-15 19:36:20] [    INFO] [itext2kg.llm_output_parsing.langchain_output_parser] üò¥ Sleeping 10.0s between batches for Unknown\n",
            "[2026-02-15 19:36:30] [    INFO] [itext2kg.llm_output_parsing.langchain_output_parser] üìã Processing batch 6/9 with 3 requests (Unknown)\n",
            "[2026-02-15 19:38:12] [    INFO] [itext2kg.llm_output_parsing.langchain_output_parser] üò¥ Sleeping 10.0s between batches for Unknown\n",
            "[2026-02-15 19:38:22] [    INFO] [itext2kg.llm_output_parsing.langchain_output_parser] üìã Processing batch 7/9 with 2 requests (Unknown)\n",
            "[2026-02-15 19:41:37] [    INFO] [itext2kg.llm_output_parsing.langchain_output_parser] üò¥ Sleeping 10.0s between batches for Unknown\n",
            "[2026-02-15 19:41:47] [    INFO] [itext2kg.llm_output_parsing.langchain_output_parser] üìã Processing batch 8/9 with 2 requests (Unknown)\n",
            "[2026-02-15 19:43:03] [    INFO] [itext2kg.llm_output_parsing.langchain_output_parser] üò¥ Sleeping 10.0s between batches for Unknown\n",
            "[2026-02-15 19:43:13] [    INFO] [itext2kg.llm_output_parsing.langchain_output_parser] üìã Processing batch 9/9 with 2 requests (Unknown)\n",
            "[2026-02-15 19:44:27] [    INFO] [itext2kg.llm_output_parsing.langchain_output_parser] ‚úÖ Successfully processed all 28 requests for Unknown\n",
            "[2026-02-15 19:44:27] [    INFO] [itext2kg.itext2kg.atom.atom] ------- Building Atomic KGs---------\n"
          ]
        },
        {
          "ename": "IndexError",
          "evalue": "list index out of range",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/content/DynamicKGConstruction/skgb/adapters/itext2kg_adapter.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(coro)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoro\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/asyncio/runners.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, debug, loop_factory)\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;31m# fail fast with short traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         raise RuntimeError(\n\u001b[0m\u001b[1;32m    192\u001b[0m             \"asyncio.run() cannot be called from a running event loop\")\n",
            "\u001b[0;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-593393436.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Run the full pipeline: PDF -> Markdown -> Chunks -> Knowledge Graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# This may take several minutes depending on the PDF size and model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"=\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/DynamicKGConstruction/skgb/pipeline.py\u001b[0m in \u001b[0;36mrun_pipeline\u001b[0;34m(input_path, cfg, recursive)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0matomic_facts_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt_obs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[{section_title}] {content}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     kg = build_kg_from_atomic_facts(\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0matomic_facts_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0matomic_facts_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mollama_base_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mollama_base_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/DynamicKGConstruction/skgb/adapters/itext2kg_adapter.py\u001b[0m in \u001b[0;36mbuild_kg_from_atomic_facts\u001b[0;34m(atomic_facts_dict, ollama_base_url, llm_model, embeddings_model, temperature, ent_threshold, rel_threshold, max_workers)\u001b[0m\n\u001b[1;32m     79\u001b[0m ):\n\u001b[1;32m     80\u001b[0m     \u001b[0;34m\"\"\"Build a KnowledgeGraph using itext2kg ATOM (async under the hood).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     return _run(\n\u001b[0m\u001b[1;32m     82\u001b[0m         _build_async(\n\u001b[1;32m     83\u001b[0m             \u001b[0matomic_facts_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0matomic_facts_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/DynamicKGConstruction/skgb/adapters/itext2kg_adapter.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(coro)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mnest_asyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mloop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_event_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoro\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/nest_asyncio.py\u001b[0m in \u001b[0;36mrun_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     96\u001b[0m                 raise RuntimeError(\n\u001b[1;32m     97\u001b[0m                     'Event loop stopped before Future completed.')\n\u001b[0;32m---> 98\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/asyncio/futures.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__log_traceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception_tb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/asyncio/tasks.py\u001b[0m in \u001b[0;36m__step_run_and_handle_result\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_must_cancel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/DynamicKGConstruction/skgb/adapters/itext2kg_adapter.py\u001b[0m in \u001b[0;36m_build_async\u001b[0;34m(atomic_facts_dict, ollama_base_url, llm_model, embeddings_model, temperature, ent_threshold, rel_threshold, max_workers)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0matom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAtom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mllm_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     kg = await atom.build_graph_from_different_obs_times(\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0matomic_facts_with_obs_timestamps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0matomic_facts_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0ment_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ment_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/itext2kg/atom/atom.py\u001b[0m in \u001b[0;36mbuild_graph_from_different_obs_times\u001b[0;34m(self, atomic_facts_with_obs_timestamps, existing_knowledge_graph, ent_threshold, rel_threshold, entity_name_weight, entity_label_weight, max_workers)\u001b[0m\n\u001b[1;32m    218\u001b[0m                                                     \u001b[0mmax_workers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                                                ):\n\u001b[0;32m--> 220\u001b[0;31m         kgs = await asyncio.gather(*[\n\u001b[0m\u001b[1;32m    221\u001b[0m                         self.build_graph(\n\u001b[1;32m    222\u001b[0m                             \u001b[0matomic_facts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0matomic_facts_with_obs_timestamps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtimestamp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/asyncio/tasks.py\u001b[0m in \u001b[0;36m__wakeup\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__wakeup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m             \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0;31m# This may also be a cancellation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/asyncio/tasks.py\u001b[0m in \u001b[0;36m__step_run_and_handle_result\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_must_cancel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/itext2kg/atom/atom.py\u001b[0m in \u001b[0;36mbuild_graph\u001b[0;34m(self, atomic_facts, obs_timestamp, existing_knowledge_graph, ent_threshold, rel_threshold, entity_name_weight, entity_label_weight, max_workers)\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"------- Building Atomic KGs---------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         atomic_kgs = await asyncio.gather(*list(map(\n\u001b[0m\u001b[1;32m    173\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_atomic_kg_from_quintuples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0mrelation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelationships\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrelation\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrelationships\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/asyncio/tasks.py\u001b[0m in \u001b[0;36m__wakeup\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__wakeup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m             \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0;31m# This may also be a cancellation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/asyncio/tasks.py\u001b[0m in \u001b[0;36m__step_run_and_handle_result\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    312\u001b[0m                 \u001b[0;31m# We use the `send` method directly, because coroutines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m                 \u001b[0;31m# don't have `__iter__` and `__next__` methods.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/itext2kg/atom/atom.py\u001b[0m in \u001b[0;36mbuild_atomic_kg_from_quintuples\u001b[0;34m(self, relationships, entity_name_weight, entity_label_weight, rel_threshold, ent_threshold, max_workers)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0matomic_kgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_into_atomic_kgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         return self.parallel_atomic_merge(\n\u001b[0m\u001b[1;32m    150\u001b[0m             \u001b[0mkgs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0matomic_kgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mrel_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrel_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/itext2kg/atom/atom.py\u001b[0m in \u001b[0;36mparallel_atomic_merge\u001b[0;34m(self, kgs, existing_kg, rel_threshold, ent_threshold, max_workers)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mexisting_kg\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mexisting_kg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_empty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_two_kgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexisting_kg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrel_threshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ment_threshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcurrent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     async def build_atomic_kg_from_quintuples(self, \n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ],
      "source": [
        "# Run the full pipeline: PDF -> Markdown -> Chunks -> Knowledge Graph\n",
        "# This may take several minutes depending on the PDF size and model\n",
        "result = run_pipeline(pdf_path, cfg)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Pipeline completed!\")\n",
        "print(f\"  Markdown dir:  {result.build_docling_dir}\")\n",
        "print(f\"  Chunks JSON:   {result.chunks_json_path}\")\n",
        "print(f\"  KG output dir: {result.kg_output_dir}\")\n",
        "print(f\"  Neo4j Cypher:  {result.neo4j_cypher_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZwUQKGPWrGx"
      },
      "source": [
        "## 5. Explore the Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pl1vQz4RWrGy"
      },
      "outputs": [],
      "source": [
        "# List all output files\n",
        "print(\"Output files:\")\n",
        "for f in sorted(result.kg_output_dir.rglob(\"*\")):\n",
        "    if f.is_file():\n",
        "        size = f.stat().st_size\n",
        "        print(f\"  {f.name:40s} {size:>8,} bytes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGRaebosWrGy"
      },
      "source": [
        "### 5.1 Construction Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfLKu3z1WrGy"
      },
      "outputs": [],
      "source": [
        "report_path = result.kg_output_dir / \"construction_report.txt\"\n",
        "print(report_path.read_text())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HcdJERWWrGy"
      },
      "source": [
        "### 5.2 Knowledge Graph JSON (Nodes & Edges)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LPnVUH0kWrGz"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "kg_json_path = result.kg_output_dir / \"knowledge_graph.json\"\n",
        "kg_data = json.loads(kg_json_path.read_text())\n",
        "\n",
        "nodes = kg_data.get(\"nodes\", [])\n",
        "edges = kg_data.get(\"edges\", [])\n",
        "\n",
        "print(f\"Total nodes: {len(nodes)}\")\n",
        "print(f\"Total edges: {len(edges)}\")\n",
        "print(f\"\\n--- First 10 Nodes ---\")\n",
        "for n in nodes[:10]:\n",
        "    print(f\"  {n['name']:40s}  label={n.get('label', '')}\")\n",
        "\n",
        "print(f\"\\n--- First 10 Edges ---\")\n",
        "for e in edges[:10]:\n",
        "    print(f\"  {e['source'][:25]:25s} --[{e['relation'][:20]}]--> {e['target'][:25]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjZfD3bGWrGz"
      },
      "source": [
        "### 5.3 Nodes & Edges as DataFrames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hgDFp89sWrGz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_nodes = pd.read_csv(result.kg_output_dir / \"kg_nodes.csv\")\n",
        "df_edges = pd.read_csv(result.kg_output_dir / \"kg_edges.csv\")\n",
        "\n",
        "print(f\"Nodes shape: {df_nodes.shape}\")\n",
        "display(df_nodes.head(10))\n",
        "\n",
        "print(f\"\\nEdges shape: {df_edges.shape}\")\n",
        "display(df_edges.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrHQR9ptWrGz"
      },
      "source": [
        "### 5.4 Interactive Knowledge Graph Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Nhl1exwWrGz"
      },
      "outputs": [],
      "source": [
        "# Display the PyVis interactive graph inline in Colab\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "viz_path = result.kg_output_dir / \"kg_visualization.html\"\n",
        "if viz_path.exists():\n",
        "    display(HTML(viz_path.read_text()))\n",
        "else:\n",
        "    print(\"Visualization file not found. PyVis may not be installed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmSxADDYWrGz"
      },
      "source": [
        "### 5.5 NetworkX Graph Stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kd6eiTmbWrGz"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "\n",
        "G = nx.read_graphml(str(result.kg_output_dir / \"knowledge_graph.graphml\"))\n",
        "\n",
        "print(f\"Graph type:       {type(G).__name__}\")\n",
        "print(f\"Number of nodes:  {G.number_of_nodes()}\")\n",
        "print(f\"Number of edges:  {G.number_of_edges()}\")\n",
        "print(f\"Density:          {nx.density(G):.4f}\")\n",
        "\n",
        "if G.number_of_nodes() > 0:\n",
        "    # Top 10 nodes by degree\n",
        "    degree_sorted = sorted(G.degree(), key=lambda x: x[1], reverse=True)\n",
        "    print(f\"\\nTop 10 nodes by degree:\")\n",
        "    for name, deg in degree_sorted[:10]:\n",
        "        print(f\"  {name:40s}  degree={deg}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvBdnaW8WrG0"
      },
      "source": [
        "### 5.6 Semantic Chunks Preview"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdns7jcQWrG0"
      },
      "outputs": [],
      "source": [
        "chunks = json.loads(result.chunks_json_path.read_text())\n",
        "print(f\"Total chunks: {len(chunks)}\\n\")\n",
        "\n",
        "for i, ch in enumerate(chunks[:3]):\n",
        "    print(f\"--- Chunk {i} ---\")\n",
        "    print(f\"  ID:      {ch.get('chunk_id', 'N/A')}\")\n",
        "    print(f\"  Section: {ch.get('section_title', 'N/A')}\")\n",
        "    content = ch.get('content', '')\n",
        "    print(f\"  Content: {content[:300]}{'...' if len(content) > 300 else ''}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEYrmS27WrG0"
      },
      "source": [
        "## 6. Neo4j Cypher Script\n",
        "\n",
        "The pipeline generates a Cypher `LOAD CSV` script you can run against a Neo4j instance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LgerAPr2WrG0"
      },
      "outputs": [],
      "source": [
        "cypher_path = result.neo4j_cypher_path\n",
        "if cypher_path.exists():\n",
        "    print(cypher_path.read_text())\n",
        "else:\n",
        "    print(\"Neo4j Cypher file not generated.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gucLqL8_WrG0"
      },
      "source": [
        "## 7. Download Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hcu7kB6GWrG0"
      },
      "outputs": [],
      "source": [
        "# Zip all outputs for download\n",
        "import shutil\n",
        "\n",
        "archive_path = shutil.make_archive(\"skgb_results\", \"zip\", \".\", \"skgb_output\")\n",
        "print(f\"Archive created: {archive_path}\")\n",
        "\n",
        "try:\n",
        "    from google.colab import files\n",
        "    files.download(archive_path)\n",
        "except ImportError:\n",
        "    print(\"Not in Colab - find the zip at:\", archive_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Dv7ZLcDWrG0"
      },
      "source": [
        "## 8. Cleanup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vg2gSL5YWrG1"
      },
      "outputs": [],
      "source": [
        "# Stop the Ollama server when done\n",
        "ollama_proc.terminate()\n",
        "ollama_proc.wait()\n",
        "print(\"Ollama server stopped.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
