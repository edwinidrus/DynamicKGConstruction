# =============================================================================
# DynamicKGConstruction - Environment Variables
# =============================================================================
# Copy this file to .env and fill in your values
# cp .env.example .env

# =============================================================================
# LLM Provider API Keys (choose based on your provider)
# =============================================================================

# OpenAI API Key (required if using llm_provider="openai")
# Get your key at: https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_api_key_here

# Anthropic API Key (required if using llm_provider="anthropic")
# Get your key at: https://console.anthropic.com/
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# =============================================================================
# Ollama Configuration (default provider - no API key needed)
# =============================================================================
# Ollama runs locally, no API key required
# Install Ollama: https://ollama.ai/
# Default base URL (change if running on different host/port)
OLLAMA_BASE_URL=http://localhost:11434

# =============================================================================
# Optional: OpenAI-Compatible API (Azure, local servers, etc.)
# =============================================================================
# OPENAI_BASE_URL=https://your-azure-endpoint.openai.azure.com/
